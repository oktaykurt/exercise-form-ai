{"cells":[{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LinearRegression\n","from ast import literal_eval\n","from random import randint\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[],"source":["# Load the data\n","data = pd.read_csv('pose-coordinates/combined_exercise_data.csv')"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[],"source":["# List of body parts\n","body_parts = ['left_hip', 'left_knee', 'left_ankle', 'left_shoulder', 'left_elbow', 'left_wrist', \n","              'right_hip', 'right_knee', 'right_ankle', 'right_shoulder', 'right_elbow', 'right_wrist']\n","\n","# Convert the string representation of list to actual list for each body part\n","for body_part in body_parts:\n","    data[body_part] = data[body_part].apply(literal_eval)\n","\n","# Split the coordinates into separate columns\n","for body_part in body_parts:\n","    data[[f'{body_part}_x', f'{body_part}_y']] = pd.DataFrame(data[body_part].to_list(), index= data.index)\n","\n","# Drop the original columns\n","data.drop(body_parts, axis=1, inplace=True)"]},{"cell_type":"code","execution_count":132,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['lunge' 'push-up' 'squat']\n"]}],"source":["# Convert the labels to numeric form\n","le = LabelEncoder()\n","data['exercise'] = le.fit_transform(data['exercise'])\n","print(le.classes_)"]},{"cell_type":"code","execution_count":133,"metadata":{},"outputs":[],"source":["# Number of videos and list to store indices of videos with missing frames\n","n_samples = len(data) // 75\n","missing_videos = []\n","\n","# Check each video for missing frames\n","for i in range(n_samples):\n","    start_index = i * 75\n","    end_index = start_index + 75\n","    if end_index > len(data):\n","        end_index = len(data)\n","    video_data = data.iloc[start_index:end_index]\n","    \n","    if len(video_data) < 75:\n","        missing_videos.append(i)\n","        continue\n","\n","# Handle videos with missing frames\n","for i in missing_videos:\n","    start_index = i * 75\n","    end_index = start_index + 75\n","    if end_index > len(data):\n","        end_index = len(data)\n","    video_data = data.iloc[start_index:end_index]\n","    \n","    # Find the missing frame indices\n","    missing_indices = []\n","    for j in range(start_index, end_index):\n","        if pd.isnull(data.iloc[j]).any():\n","            missing_indices.append(j)\n","    \n","    # Handle each missing frame\n","    for missing_index in missing_indices:\n","        # Fit a linear regression model using the preceding and succeeding frames\n","        model = LinearRegression()\n","        if missing_index == start_index:  # if the missing frame is the first frame\n","            X_train = np.array([missing_index + 1, missing_index + 2]).reshape(-1, 1)\n","            y_train = data.iloc[[missing_index + 1, missing_index + 2]]\n","        elif missing_index == end_index - 1:  # if the missing frame is the last frame\n","            X_train = np.array([missing_index - 1, missing_index - 2]).reshape(-1, 1)\n","            y_train = data.iloc[[missing_index - 1, missing_index - 2]]\n","        else:  # if the missing frame is in between\n","            X_train = np.array([missing_index - 1, missing_index + 1]).reshape(-1, 1)\n","            y_train = data.iloc[[missing_index - 1, missing_index + 1]]\n","        \n","        # Drop the 'exercise' column since it's not used for prediction\n","        y_train = y_train.drop('exercise', axis=1)\n","        \n","        # Fit the model\n","        model.fit(X_train, y_train)\n","        \n","        # Predict the missing frame\n","        y_pred = model.predict(np.array(missing_index).reshape(-1, 1))\n","        \n","        # Replace the missing frame in the original data with the predicted frame\n","        data.iloc[missing_index] = np.append(y_pred.flatten(), video_data['exercise'].mode()[0])\n","\n","# Reshape the data and split it into training and test sets\n","n_samples = len(data) // 75\n","n_time_steps = 75\n","n_features = len(body_parts) * 2\n","X = []\n","y = []\n","\n","# Iterate over each video\n","for i in range(n_samples):\n","    start_index = i * 75\n","    end_index = start_index + 75\n","    if end_index > len(data):\n","        end_index = len(data)\n","    video_data = data.iloc[start_index:end_index]\n","    \n","    # Only use complete videos\n","    if len(video_data) == 75:\n","        X_video = video_data.drop(['frame_time', 'exercise'], axis=1).to_numpy().reshape(1, n_time_steps, n_features)\n","        y_video = np.array([video_data['exercise'].iloc[0]])  # Only select the first label of each video\n","        X.append(X_video)\n","        y.append(y_video)\n","\n","# Convert the lists to numpy arrays\n","X = np.concatenate(X)\n","y = np.concatenate(y)\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=randint(1,100))\n"]},{"cell_type":"code","execution_count":134,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss: 1.0673152208328247\n","Epoch 10, Loss: 0.5497145056724548\n","Epoch 20, Loss: 0.5685036778450012\n","Epoch 30, Loss: 0.4033287465572357\n","Epoch 40, Loss: 0.3152116537094116\n","Epoch 50, Loss: 0.19971963763237\n","Epoch 60, Loss: 0.14369754493236542\n","Epoch 70, Loss: 0.09214992076158524\n","Epoch 80, Loss: 0.05746317654848099\n","Epoch 90, Loss: 0.03489897772669792\n","Epoch 100, Loss: 0.02433663234114647\n","Epoch 110, Loss: 0.019703984260559082\n","Epoch 120, Loss: 0.020219119265675545\n","Epoch 130, Loss: 0.019350627437233925\n","Epoch 140, Loss: 0.016209637746214867\n","Epoch 150, Loss: 0.012933320365846157\n","Epoch 160, Loss: 0.011495879851281643\n","Epoch 170, Loss: 0.010981163941323757\n","Epoch 180, Loss: 0.011295044794678688\n","Epoch 190, Loss: 0.00987355224788189\n","Epoch 200, Loss: 0.008261880837380886\n","Epoch 210, Loss: 0.005602786783128977\n","Epoch 220, Loss: 0.007739420980215073\n","Epoch 230, Loss: 0.006769430357962847\n","Epoch 240, Loss: 0.005196459125727415\n"]}],"source":["# Check if GPU is available and if not, use CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Convert the data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)  # Change dtype to long\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)  # Change dtype to long\n","\n","\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout_rate):\n","        super(LSTMModel, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device) \n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n","        \n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.batchnorm(out[:, -1, :])\n","        out = self.dropout(out)\n","        out = self.fc(out)\n","        return out\n","\n","# Define the model with 3 output neurons\n","model = LSTMModel(n_features, 32, 3, 2, 0.2).to(device)\n","\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()  # Change loss function to CrossEntropyLoss\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train the model\n","num_epochs = 250\n","for epoch in range(num_epochs):\n","    model.train()\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor)\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if epoch % 10 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.item()}')\n","\n","# Evaluate the model\n","model.eval()\n","with torch.no_grad():\n","    y_test_pred = model(X_test_tensor)\n","    # Apply argmax to the predictions\n","    y_test_pred = torch.argmax(y_test_pred, dim=1)"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: % 100.0\n"]}],"source":["# Calculate accuracy\n","accuracy = (y_test_pred == y_test_tensor).sum().item() / len(y_test_tensor)\n","print('Accuracy: %', accuracy * 100)"]},{"cell_type":"code","execution_count":136,"metadata":{},"outputs":[],"source":["# Save the model\n","torch.save(model.state_dict(), 'exercise_classification_model.pth')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
